{
  "cells": [
    {
      "metadata": {
        "_uuid": "3be2f0dad24b2154cb80c493aba7841e6c447ade"
      },
      "cell_type": "markdown",
      "source": "# Problem Statement\nTo predict if a kickstarter project will be successful or will fail before its actual deadline. Also identify the factors that determine the success rate of a project.\n\n\n# Solution Notebook\nThis notebook basically has 4 steps/ modules:\n    1. Data Understanding (EDA) and Preprocessing\n    2. Feature Engineering and heuristic feature selection\n    3. Model Building\n        3A. XGBoost\n        3B. Random Forest\n        3C. LGBM (2 versions: with one-hot encoded features and with categorical features at integer-category columns)\n        3D. Ensemble Models- ormal Averaging and AdaBoosting\n    4. Feature importance\n    \nThe best accuracy obtained was 70.3% accuracy on Test Data from LGBM (version 2)"
    },
    {
      "metadata": {
        "_uuid": "88095ebec76619f69af5aa3f6fb43493b745e543"
      },
      "cell_type": "markdown",
      "source": "## Setting up the requires libraries and packages"
    },
    {
      "metadata": {
        "_uuid": "ccd53887439ec5be5b7c5e03869463e08332af4f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfrom datetime import datetime\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nimport string\n#import itertools\n#from itertools import product",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fa4d43fc06b54ea69d82e17f14af4e7a4bc4cef2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#setting working directory\n#os.chdir(\"/home/srishti/Srishti Saha- backup/misc/personal/kickstarter_projects\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5a9340428ee763c20d58fe025340e1486eb4383"
      },
      "cell_type": "markdown",
      "source": "## Importing a dataset"
    },
    {
      "metadata": {
        "_uuid": "9042e9b10d782de3b1eec47778bc45b88443765a",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read in data\nkickstarters_2017 = pd.read_csv(\"../input/ks-projects-201801.csv\")\nkickstarters_2017.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8d277e06f443a117a9d95bdbd8334ae2a1b3146f"
      },
      "cell_type": "markdown",
      "source": "## Basic Tests and EDA on input data"
    },
    {
      "metadata": {
        "_uuid": "c4d448315585243cb96da92b94252f00c09cf8fd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#printing all summary of the kickstarter data\n#this will give the dimensions of data set : (rows, columns)\nprint(kickstarters_2017.shape)\n#columns and data types\nprint(kickstarters_2017.info())\n#basic stats of columns\nprint(kickstarters_2017.describe())\n#number of unique values in all columns\nprint(kickstarters_2017.nunique())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f4d64072828c950f732e85f18d7fc298d6963842"
      },
      "cell_type": "markdown",
      "source": "The above stats help us reaching the following conclusions:\n1. the data is at ID level (unique of ID=number of rows)\n2. The numerical data fields are: goal, pledged, backers, usd_pledged, usd_pledged_real,usd_goal_real"
    },
    {
      "metadata": {
        "_uuid": "d0e295c1922ebcd2d199011823adda5f24452214"
      },
      "cell_type": "markdown",
      "source": "#### Understanding Variables in the Dataset\n\nThe dataset has 15 variablesincluding ID. SInce ID is the level of the dataset, we can set it as the index of the ata later. Variables like name, currency, deadline, launched date and country as self explanatory. Explanations of some key variables are as follows:\n\nMain_Category: There are 15 main categories for the project. These main categories broadly classify projects based on topic and genre they belong to.\n\nCategory: Main Categories are further sub divided in categories to give more general idea of the project. For example, Main Category “Technology” has 15 categories like Gadgets, Web, Apps, Software etc. There are 159 total categories.\n\nGoal: This is the goal amount which the company need to raise to start its project. The goal amount is important variable for company as if it is too high, the project may fail to raise that amount of money and be unsuccessful. If it is too low, then it may reach its goal soon and backers may not be interested to pledge more.\n\nPledged: This is amount raised by the company through its backers. On Kickstarter, if total amount pledged is lower than goal, then the project is unsuccessful and the start-up company doesn’t receive any fund. If pledged amount is more than the goal, the company is considered successful. The variable “usd pledged” is amount of money raised in US dollars.\n\nNumber of Backers: These are number of people who have supported the project by pledging some amount."
    },
    {
      "metadata": {
        "_uuid": "8b3c98d9942b42b4859bdcd4778386900feb5332",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Distribution of data across state\npercent_success = round(kickstarters_2017[\"state\"].value_counts() / len(kickstarters_2017[\"state\"]) * 100,2)\n\nprint(\"State Percent: \")\nprint(percent_success)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "847bb001f7c678933dbf9918aa07c456eb464f3a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#renaming column usd_pledged as there is no '_' in the actual dataset variable name\ncol_names_prev=list(kickstarters_2017)\ncol_names_new= ['ID',\n 'name',\n 'category',\n 'main_category',\n 'currency',\n 'deadline',\n 'goal',\n 'launched',\n 'pledged',\n 'state',\n 'backers',\n 'country',\n 'usd_pledged',\n 'usd_pledged_real',\n 'usd_goal_real']\nkickstarters_2017.columns= col_names_new",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f1b390374c1cdd97917f12c65a103db24bf838d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#segregating the variables as categorical and constinuous\ncat_vars=[ 'category', 'main_category', 'currency','country']\ncont_vars=['goal', 'pledged', 'backers','usd_pledged','usd_pledged_real','usd_goal_real']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b789a30e3d2d37d7a82782afde60fa26ef1e5cd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#correlation of continuous variables\nkickstarters_2017[cont_vars].corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af49ce4663badd844da0839021a3ec6a8cfee0d6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#setting unique ID as index of the table\n#this is because the ID column will not be used in the algorithm. yet it is needed to identify the project\ndf_kick= kickstarters_2017.set_index('ID')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fa5cb9212551027ac6bbe724b11c36c37352b334",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Filtering only for successful and failed projects\nkick_projects = df_kick[(df_kick['state'] == 'failed') | (df_kick['state'] == 'successful')]\n#converting 'successful' state to 1 and failed to 0\nkick_projects['state'] = (kick_projects['state'] =='successful').astype(int)\nprint(kick_projects.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0cfc679097619e4515512ad7a49a4a9a8ebe947",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#checking distribution of projects across various main categories\nkick_projects.groupby(['main_category','state']).size()\n#kick_projects.groupby(['category','state']).size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eceeeb02ed0a0276279ca5f19434c36f20ec0176",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#correlation of continuous variables with the dependent variable\nkick_projects[['goal', 'pledged', 'backers','usd_pledged','usd_pledged_real','usd_goal_real','state']].corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "894d8083a1527cf5b43dc4e0dedfc0150f4ef55c"
      },
      "cell_type": "markdown",
      "source": "## Feature Engineering"
    },
    {
      "metadata": {
        "_uuid": "51cc44af7296d68ce3cc012d280d228d6e52e12f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating derived metrics/ features\n\n#converting the date columns from string to date format\n#will use it to derive the duration of the project\nkick_projects['launched_date'] = pd.to_datetime(kick_projects['launched'], format='%Y-%m-%d %H:%M:%S')\nkick_projects['deadline_date'] = pd.to_datetime(kick_projects['deadline'], format='%Y-%m-%d %H:%M:%S')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3bf27a43462e2b1bdb4e4e3f3d48da088f53b763",
        "trusted": true
      },
      "cell_type": "code",
      "source": "kick_projects= kick_projects.sort_values('launched_date',ascending=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "106abd8d6e2fda9bff7cf5d8ed1ee28f1f833362",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "kick_projects.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1011e2c0295eb372eed17d6d6f378e7ddc28389d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating features from the project name\n\n#length of name\nkick_projects['name_len'] = kick_projects.name.str.len()\n\n# presence of !\nkick_projects['name_exclaim'] = (kick_projects.name.str[-1] == '!').astype(int)\n\n# presence of !\nkick_projects['name_question'] = (kick_projects.name.str[-1] == '?').astype(int)\n\n# number of words in the name\nkick_projects['name_words'] = kick_projects.name.apply(lambda x: len(str(x).split(' ')))\n\n# if name is uppercase\nkick_projects['name_is_upper'] = kick_projects.name.str.isupper().astype(float)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf491e3e550530dcdf506ef1663d5abb3adbd3b9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# normalizing goal by applying log\nkick_projects['goal_log'] = np.log1p(kick_projects.goal)\n#creating goal features to check what range goal lies in\nkick_projects['Goal_10'] = kick_projects.goal.apply(lambda x: x // 10)\nkick_projects['Goal_1000'] = kick_projects.goal.apply(lambda x: x // 1000)\nkick_projects['Goal_100'] = kick_projects.goal.apply(lambda x: x // 100)\nkick_projects['Goal_500'] = kick_projects.goal.apply(lambda x: x // 500)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b9ff90d44cad2193b8e18966382f66819bea372",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#features from date column\nkick_projects['duration']=(kick_projects['deadline_date']-kick_projects['launched_date']).dt.days\n#the idea for deriving launched quarter month year is that perhaps projects launched in a particular year/ quarter/ month might have a low success rate\nkick_projects['launched_quarter']= kick_projects['launched_date'].dt.quarter\nkick_projects['launched_month']= kick_projects['launched_date'].dt.month\nkick_projects['launched_year']= kick_projects['launched_date'].dt.year\nkick_projects['launched_week']= kick_projects['launched_date'].dt.week",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "837a3baa8aa0dae82ae5033c7302d844b000eed9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#additional features from goal, pledge and backers columns\nkick_projects.loc[:,'goal_reached'] = kick_projects['pledged'] / kick_projects['goal'] # Pledged amount as a percentage of goal.\n#The above field will be used to compute another metric\n# In backers column, impute 0 with 1 to prevent undefined division.\nkick_projects.loc[kick_projects['backers'] == 0, 'backers'] = 1 \nkick_projects.loc[:,'pledge_per_backer'] = kick_projects['pledged'] / kick_projects['backers'] # Pledged amount per backer.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2ea3f2449798864280f007eb7189d740cce69123",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#will create percentile buckets for the goal amount in a category\nkick_projects['goal_cat_perc'] =  kick_projects.groupby(['category'])['goal'].transform(\n                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =[1,2,3]))\n\n#will create percentile buckets for the duration in a category\nkick_projects['duration_cat_perc'] =  kick_projects.groupby(['category'])['duration'].transform(\n                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =False, duplicates='drop'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6b225db33392d67683aa8496fb79d1269e4f7d61",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating a metric to see number of competitors for a given project in a given quarter\n#number of participants in a given category, that launched in the same year and quarter and in the same goal bucket\nks_particpants_qtr=kick_projects.groupby(['category','launched_year','launched_quarter','goal_cat_perc']).count()\nks_particpants_qtr=ks_particpants_qtr[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_qtr.reset_index(inplace=True)\n\n#creating a metric to see number of competitors for a given project in a given month\n#number of participants in a given category, that launched in the same year and month and in the same goal bucket\nks_particpants_mth=kick_projects.groupby(['category','launched_year','launched_month','goal_cat_perc']).count()\nks_particpants_mth=ks_particpants_mth[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_mth.reset_index(inplace=True)\n\n#creating a metric to see number of competitors for a given project in a given week\n#number of participants in a given category, that launched in the same year and week and in the same goal bucket\nks_particpants_wk=kick_projects.groupby(['category','launched_year','launched_week','goal_cat_perc']).count()\nks_particpants_wk=ks_particpants_wk[['name']]\n#since the above table has all group by columns created as index, converting them into columns\nks_particpants_wk.reset_index(inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3e4ed868f5a015b1628864cb18974a55c7c45719",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#renaming columns of the derived table\ncolmns_qtr=['category', 'launched_year', 'launched_quarter', 'goal_cat_perc', 'participants_qtr']\nks_particpants_qtr.columns=colmns_qtr\n\ncolmns_mth=['category', 'launched_year', 'launched_month', 'goal_cat_perc', 'participants_mth']\nks_particpants_mth.columns=colmns_mth\n\ncolmns_wk=['category', 'launched_year', 'launched_week', 'goal_cat_perc', 'participants_wk']\nks_particpants_wk.columns=colmns_wk",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8489bc88cd825f37ac74e9398c639f062fd7fba6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#merging the particpants column into the base table\nkick_projects = pd.merge(kick_projects, ks_particpants_qtr, on = ['category', 'launched_year', 'launched_quarter','goal_cat_perc'], how = 'left')\nkick_projects = pd.merge(kick_projects, ks_particpants_mth, on = ['category', 'launched_year', 'launched_month','goal_cat_perc'], how = 'left')\nkick_projects = pd.merge(kick_projects, ks_particpants_wk, on = ['category', 'launched_year', 'launched_week','goal_cat_perc'], how = 'left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e093fbe166f5ee625f0b7a2d2a4406bed9deac59",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating 2 metrics to get average pledge per backer for a category in a year according to the goal bucket it lies in and the success rate ie average pledged to goal ratio for the category and goal bucket in this year\n#using pledge_per_backer (computed earlier) and averaging it by category in a launch year\nks_ppb_goal=pd.DataFrame(kick_projects.groupby(['category','launched_year','goal_cat_perc'])['pledge_per_backer','goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_goal.reset_index(inplace=True)\n#renaming column\nks_ppb_goal.columns= ['category','launched_year','goal_cat_perc','avg_ppb_goal','avg_success_rate_goal']\n\n#creating a metric: the success rate ie average pledged to goal ratio for the category in this year\nks_ppb_duration=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal_reached'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nks_ppb_duration.reset_index(inplace=True)\n#renaming column\nks_ppb_duration.columns= ['category','launched_year','duration_cat_perc','avg_success_rate_duration']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "733f7047afab702b56a62e7ef330f33d450e1825",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#merging the particpants column into the base table\nkick_projects = pd.merge(kick_projects, ks_ppb_goal, on = ['category', 'launched_year','goal_cat_perc'], how = 'left')\nkick_projects = pd.merge(kick_projects, ks_ppb_duration, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1a6e2cde06e1d1cad7c000c3ffc5852a151510ce",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating 2 metrics: mean and median goal amount\nmedian_goal_cat=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal'].median())\n#since the above table has all group by columns created as index, converting them into columns\nmedian_goal_cat.reset_index(inplace=True)\n#renaming column\nmedian_goal_cat.columns= ['category','launched_year','duration_cat_perc','median_goal_year']\n\nmean_goal_cat=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal'].mean())\n#since the above table has all group by columns created as index, converting them into columns\nmean_goal_cat.reset_index(inplace=True)\n#renaming column\nmean_goal_cat.columns= ['category','launched_year','duration_cat_perc','mean_goal_year']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad750790b5c298591a2a43c24b4e7a72f7aaae1a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#merging the particpants column into the base table\nkick_projects = pd.merge(kick_projects, median_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')\nkick_projects = pd.merge(kick_projects, mean_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9d93417fce293d83904a619120a29b9f76e6ee5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(kick_projects.shape)\nkick_projects[:3]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd90aa6effcd7d3214e9cffa0bac173867ba341f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# replacing all 'N,0\"' values in the country column with 'NZERO' to avoid discrepancies while one hot encoding\nkick_projects = kick_projects.replace({'country': 'N,0\"'}, {'country': 'NZERO'}, regex=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e9805dac04702df31631c2858f145eb45fab33a2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "list(kick_projects)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4de4f4f39895672c6b61d3b898bbf839ba751bf1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#selecting the needed fields only\n#this will lead to the final features list\n\n#creating a list of columns to be dropped\ndrop_columns= ['name','launched','deadline','launched_date','deadline_date','pledged','backers','usd_pledged','usd_pledged_real','pledge_per_backer','goal_reached']\n#dropping columns above\nkick_projects.drop(drop_columns, axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dbc5c211ab9cf50dfcca0086c58cb42dd4860826",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#these functions will be used on the textual column entries to remove '&','-' or white spaces\ndef replace_ampersand(val):\n    if isinstance(val, str):\n        return(val.replace('&', 'and'))\n    else:\n        return(val)\n\ndef replace_hyphen(val):\n    if isinstance(val, str):\n        return(val.replace('-', '_'))\n    else:\n        return(val)    \n    \ndef remove_extraspace(val):\n        if isinstance(val, str):\n            return(val.strip())\n        else:\n            return(val) \n\ndef replace_space(val):\n        if isinstance(val, str):\n            return(val.replace(' ', '_'))\n        else:\n            return(val)         ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bdda369b978137ff76ac60204e77bdded576b964",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#apply those functions to all cat columns\n#this will remove special characters from the character columns.\n#Since these fileds will be one-hot encoded, the column names so derived should be compatible with the requied format\nkick_projects['category'] = kick_projects['category'].apply(remove_extraspace)\nkick_projects['category'] = kick_projects['category'].apply(replace_ampersand)\nkick_projects['category'] = kick_projects['category'].apply(replace_hyphen)\nkick_projects['category'] = kick_projects['category'].apply(replace_space)\n\nkick_projects['main_category'] = kick_projects['main_category'].apply(remove_extraspace)\nkick_projects['main_category'] = kick_projects['main_category'].apply(replace_ampersand)\nkick_projects['main_category'] = kick_projects['main_category'].apply(replace_hyphen)\nkick_projects['main_category'] = kick_projects['main_category'].apply(replace_space)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "030ea50e9a1ecc0bbefb7b03b537e9e15e5265bb",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#missing value treatment\n# Check for nulls.\nkick_projects.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f650fd1b3060ec8e9da27526eb4fbae49042dc1c"
      },
      "cell_type": "markdown",
      "source": "There are only 3 rows with nulls, and the rows with nulls have no names. These rows can be removed."
    },
    {
      "metadata": {
        "_uuid": "1df9f84243000b01b8a31baba3ffdc8897d44ba1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#dropping all rows that have any nulls\nkick_projects=kick_projects.dropna() ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "82fbc8cb73fddb3818a55d083f2fa8dd739e0de4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Check for nulls again.\nkick_projects.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2f39bd5e599df08a66a2a90bf9e2766313107dfe"
      },
      "cell_type": "markdown",
      "source": "No nulls, we are good to go"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ddc24b47ea6c3742f279a862e0a945305e0583f0"
      },
      "cell_type": "code",
      "source": "#creating a backup copy of the input dataset\nkick_projects_copy= kick_projects.copy()\n\nkick_projects_copy[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f698e3f5dac9d2e6c3aa9e8ffb74fdfbafa10a4"
      },
      "cell_type": "code",
      "source": "for c in kick_projects.columns:\n    col_type = kick_projects[c].dtype\n    if col_type == 'object' :\n        a=kick_projects[c].unique()\n        keys= range(a.shape[0])\n        diction={}\n        for idx,val in enumerate(a):\n            diction[idx] = a[idx]\n        diction = {v: k for k, v in diction.items()}\n        print(diction)\n        # traversing through dataframe \n        # Gender column and writing \n        # values where key matches \n        kick_projects_copy[c] = [diction[item] for item in kick_projects_copy[c]] \n        kick_projects_copy[c] = kick_projects_copy[c].astype('category')\n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1624702e4d33399ea9f22bfb94186510b2b628a5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# One-Hot encoding to convert categorical columns to numeric\nprint('start one-hot encoding')\n\nkick_projects_ip = pd.get_dummies(kick_projects, prefix = [ 'category', 'main_category', 'currency','country'],\n                             columns = [ 'category', 'main_category', 'currency','country'])\n    \n#this will have created 1-0 flag columns (like a sparse matrix)    \nprint('ADS dummy columns made')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f55f59fceac8fd7dfdc96c11a7013edf53001784",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating 2 arrays: features and response\n\n#features will have all independent variables\nfeatures=list(kick_projects_ip)\nfeatures.remove('state')\n#response has the target variable\nresponse= ['state']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5800d73f5738e7e2f54fb41e42b849967120c76a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating a backup copy of the input dataset\nkick_projects_ip_copy= kick_projects_ip.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c3d577db0d67603a11ea8c76a3f85f7b7db4cabe",
        "trusted": true
      },
      "cell_type": "code",
      "source": "kick_projects_ip[features].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "db431e0ede0ca45a6b2a471fc674ba7afe04c868",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# normalize the data attributes\nkick_projects_ip_scaled_ftrs = pd.DataFrame(preprocessing.normalize(kick_projects_ip[features]))\nkick_projects_ip_scaled_ftrs.columns=list(kick_projects_ip[features])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0064f92ba73f90d19564565e9bdd8bc4cb8950cc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "kick_projects_ip_scaled_ftrs[:3]\n#kick_projects_ip[features].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c36fa9122b2959ac988bf21fa1a5bac9a93a090"
      },
      "cell_type": "markdown",
      "source": "## Model Building"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "0be2ac6a4e06d00eb01a6396e1907f59ecf637bc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating test and train dependent and independent variables\n#Split the data into test and train (30-70: random sampling)\n#will be using the scaled dataset to split \ntrain_ind, test_ind, train_dep, test_dep = train_test_split(kick_projects_ip_scaled_ftrs, kick_projects_ip[response], test_size=0.3, random_state=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6d206e0f39bc7994e2fbd4783f12ab6b81e08412"
      },
      "cell_type": "markdown",
      "source": "### XGBoost classifier"
    },
    {
      "metadata": {
        "_uuid": "6ff3429e381226150fd5b646307975c8bdae00e6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from xgboost import XGBClassifier\nfrom sklearn import model_selection",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0210274a3da03ef9e7164130ecd91e0cb3ab6e2"
      },
      "cell_type": "code",
      "source": "#def timer(start_time=None):\n#    if not start_time:\n#        start_time = datetime.now()\n#        return start_time\n#    elif start_time:\n#        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n#        tmin, tsec = divmod(temp_sec, 60)\n#        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1b1b4e01c8e6d452ba1391142b26389de662554",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# defining the XGBoost model\nxgb_model = XGBClassifier(\n n_estimators= 1200,\n learning_rate= 0.08,\n max_depth= 5,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic'\n )\n\n\n# Tried doing a grid search but commented it out for the amount of time it takes\n## Defining parameters\n#n_estimators = [500,1000, 1200]\n#learning_rate = [0.0001, 0.01,0.1, 0.3]\n#param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n\n## Starting stratified Kfold\n#kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n#random_search = model_selection.RandomizedSearchCV(xgb_model, param_grid, scoring=\"neg_log_loss\", n_jobs=4, cv=kfold.split(train_ind[features], train_dep[response]), n_iter=12)\n\n## fitting the random search\n#start_time = timer(None)\n#random_result = random_search.fit(train_ind[features], train_dep[response])\n#timer(start_time) # timing ends here for \"start_time\" variable",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e04534dfc0c1f91c505148c4cc4234e4015ee2e1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# model fitting\nxgb_model=xgb_model.fit(train_ind[features], train_dep[response])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "724c79be2a5746e2c4752f07d3b2e0a823480f25"
      },
      "cell_type": "markdown",
      "source": "#### Prediction XGB"
    },
    {
      "metadata": {
        "_uuid": "64ed9455c9f9d0b6d0e6580a2885e38f2a4a4f7f",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Predict the on the train_data\ntest_ind[\"Pred_state_XGB_2\"] = xgb_model.predict(test_ind[features])\n\n# Predict the on the train_data\ntrain_ind[\"Pred_state_XGB_2\"] = xgb_model.predict(train_ind[features])\n\n# Predict the on the train_data\nkick_projects_ip[\"Pred_state_XGB_2\"] = xgb_model.predict(kick_projects_ip_scaled_ftrs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e29cc17bff6fee97c98be177509bd298a944a9fb"
      },
      "cell_type": "markdown",
      "source": "#### Evaluating XGB classifier"
    },
    {
      "metadata": {
        "_uuid": "0f2fbe29b192f0ecac37664717e00ed1f30a5a24",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print (\"Test Accuracy :: \",accuracy_score(test_dep[response], xgb_model.predict(test_ind[features])))\nprint (\"Train Accuracy :: \",accuracy_score(train_dep[response], xgb_model.predict(train_ind[features])))\nprint (\"Complete Accuracy  :: \",accuracy_score(kick_projects_ip[response], xgb_model.predict(kick_projects_ip_scaled_ftrs)))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_XGB_2\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3f142b0941e1d304d35952700008dd593f6d928"
      },
      "cell_type": "markdown",
      "source": "#### Deriving important features for predicting state of kickstarter projects"
    },
    {
      "metadata": {
        "_uuid": "58aaf501abee2ab96efe931fbf943a955d4b6c7f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Feature importances\nftr_imp=zip(features,xgb_model.feature_importances_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "da79d29ee91d66e0c0c44ef0278243677cc008b2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "for values in ftr_imp:\n    print(values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a2ee3c3e7027f4bb820d3b17ecf8f38d28981805",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating a dataframe\nfeature_imp=pd.DataFrame(list(zip(features,xgb_model.feature_importances_)))\ncolumn_names= ['features','XGB_imp']\nfeature_imp.columns= column_names",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9857b6c7b7269f417de35bcccce8526c1c5376c9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# sort in descending order of importances\nfeature_imp= feature_imp.sort_values('XGB_imp',ascending=False)\nfeature_imp[:15]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9f712fc0404acc318c0689f7afecd0eb4f31fa08"
      },
      "cell_type": "markdown",
      "source": "### Random Forest Classifier"
    },
    {
      "metadata": {
        "_uuid": "1ecb80b57faf8468b70cb35fece0714e39ceb5ad",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nimport math",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "670aafbfa166cb69bfb46f9642a9a90b621e296d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "features_count = train_ind.shape[1]\n\nparameters_rf = {'n_estimators':[50], 'max_depth':[20], 'max_features': \n                     [math.floor(np.sqrt(features_count)), math.floor(features_count/3)]}\n\ndef random_forest_classifier(features, target):\n    \"\"\"\n    To train the random forest classifier with features and target data\n    :param features:\n    :param target:\n    :return: trained random forest classifier\n    \"\"\"\n    clf = RandomForestClassifier(n_estimators=50,criterion='gini' ,max_depth=20, max_features=2)\n    clf.fit(features, target)\n    return clf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bce2d1229fb9653acc4782c94cf88725468df631",
        "trusted": true
      },
      "cell_type": "code",
      "source": "trained_model_RF= random_forest_classifier(train_ind[features], train_dep[response])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1532a88aaa09ff4c747fb18770ad8ead88c8451d"
      },
      "cell_type": "markdown",
      "source": "#### Predictions using RF"
    },
    {
      "metadata": {
        "_uuid": "6871768b3454e816111f608efdc49a45e051795a",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Predict the on the train_data\ntest_ind[\"Pred_state_RF\"] = trained_model_RF.predict(test_ind[features])\n\n# Predict the on the train_data\ntrain_ind[\"Pred_state_RF\"] = trained_model_RF.predict(train_ind[features])\n\n# Predict the on the train_data\nkick_projects_ip[\"Pred_state_RF\"] = trained_model_RF.predict(kick_projects_ip_scaled_ftrs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "078331da45fac7083db6cfbb604ea5478247f167"
      },
      "cell_type": "markdown",
      "source": "#### Accuracies of RF"
    },
    {
      "metadata": {
        "_uuid": "77ef1e566a88477e8fc2e180efce8c19b47fc692",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Train and Test Accuracy\nprint (\"Train Accuracy :: \", accuracy_score(train_dep[response], trained_model_RF.predict(train_ind[features])))\nprint (\"Test Accuracy  :: \", accuracy_score(test_dep[response], trained_model_RF.predict(test_ind[features])))\nprint (\"Complete Accuracy  :: \", accuracy_score(kick_projects_ip[response], trained_model_RF.predict(kick_projects_ip_scaled_ftrs)))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_RF\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "56cbaf931102192672ce8d2764ba43a5a6afb252"
      },
      "cell_type": "markdown",
      "source": "#### Key drivers from Random Forest"
    },
    {
      "metadata": {
        "_uuid": "8a886d272776b1fb1bd84a18d3b022aeaf1f0533",
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Feature importances\nftr_imp_rf=zip(features,trained_model_RF.feature_importances_)\nfor values in ftr_imp_rf:\n    print(values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "515e86e8f01fd917be06b396441ac519ea3654f1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_imp_RF=pd.DataFrame(list(zip(features,trained_model_RF.feature_importances_)))\ncolumn_names_RF= ['features','RF_imp']\nfeature_imp_RF.columns= column_names_RF",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "86554393c6a1b853e8005d4047750cf2fb57a3fc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_imp_RF= feature_imp_RF.sort_values('RF_imp',ascending=False)\nfeature_imp_RF[:15]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "792791cc7879822cd2deae338855a9122c9f4045"
      },
      "cell_type": "markdown",
      "source": "### LGBM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ee02fd601777ff514a7892da41e521f19e54a5e"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae42a0cf255c97d8bdae5ed6f864bce8c51c117f"
      },
      "cell_type": "code",
      "source": "#create LGBM classifier model\ngbm_model = lgb.LGBMClassifier(\n        boosting_type= \"dart\",\n        n_estimators=1300,\n        learning_rate=0.08,\n        num_leaves=35,\n        colsample_bytree=.8,\n        subsample=.9,\n        max_depth=9,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n)\n\n# LGBM with one-hot encoded features\n#fit the model on training data\ngbm_model=gbm_model.fit(train_ind[features], \n            train_dep[response], \n              verbose=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "468aa48a034f9f854b26c361e6c085342ac41cd7"
      },
      "cell_type": "markdown",
      "source": "#### Predictions using LGBM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9420f52788e129036c145a7cc711580f0123438e"
      },
      "cell_type": "code",
      "source": "# Predict the on the train_data\ntest_ind[\"Pred_state_LGB\"] = gbm_model.predict(test_ind[features])\n\n# Predict the on the train_data\ntrain_ind[\"Pred_state_LGB\"] = gbm_model.predict(train_ind[features])\n\n# Predict the on the train_data\nkick_projects_ip[\"Pred_state_LGB\"] = gbm_model.predict(kick_projects_ip_scaled_ftrs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a9831f7d5e1f2260789652f3dc56c44e440b4ae"
      },
      "cell_type": "markdown",
      "source": "#### Model Evaluation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78ed1de5995540c29b22a21d21ddb8b4b1514061"
      },
      "cell_type": "code",
      "source": "# Train and Test Accuracy\nprint (\"Train Accuracy :: \", accuracy_score(train_dep[response], gbm_model.predict(train_ind[features])))\nprint (\"Test Accuracy  :: \", accuracy_score(test_dep[response], gbm_model.predict(test_ind[features])))\nprint (\"Complete Accuracy  :: \", accuracy_score(kick_projects_ip[response], gbm_model.predict(kick_projects_ip_scaled_ftrs)))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_LGB\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96f88e11df36b9d3f631a5e7e9366625bc6da9e8"
      },
      "cell_type": "code",
      "source": "# classification matrix\nprint('\\nClassification metrics')\nprint(classification_report(y_true=test_dep[response], y_pred=test_ind[\"Pred_state_LGB\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "345294fa9798733477061efd095fb221d14cf92a"
      },
      "cell_type": "markdown",
      "source": "#### Feature Importances"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "513b91cb4f8eb43df7e0cd49c1d3f816662f1312"
      },
      "cell_type": "code",
      "source": "## Feature importances\nftr_imp_lgb=zip(features,gbm_model.feature_importances_)\n\nfor values in ftr_imp_lgb:\n    print(values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "504e9e77ba7db7a85eca3081118b07602f834592"
      },
      "cell_type": "code",
      "source": "feature_imp_lgb=pd.DataFrame(list(zip(features,gbm_model.feature_importances_)))\ncolumn_names_lgb= ['features','LGB_imp']\nfeature_imp_lgb.columns= column_names_lgb\n\nfeature_imp_lgb= feature_imp_lgb.sort_values('LGB_imp',ascending=False)\nfeature_imp_lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3158973a60a7767a10ffc63502b9a4b9656621d"
      },
      "cell_type": "markdown",
      "source": "### LGBM with categorical level as category columns; no normalization of numerical columns"
    },
    {
      "metadata": {
        "_uuid": "a5d212775e3d8b0f6a4a31013f62b7261b3046fe"
      },
      "cell_type": "markdown",
      "source": "Let us call this one LGB2 model for easy reference later"
    },
    {
      "metadata": {
        "_uuid": "c8befc36711438f8bf59da1585637894b501ba2b"
      },
      "cell_type": "markdown",
      "source": "Doing this exercise with LGBM again, but without one-hot encoding the categorical features. Instead, I have assigned an integer value to each of the 'category', 'main_category', 'currency' and 'country' values. This will then be passed as category columns to LGBM using the 'categorical_feature' argument of the LGBMClassifier.fit function"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94484d41488a093d374c106eb1829e8dbc6e875b"
      },
      "cell_type": "code",
      "source": "#creating features and response list\nfeatures_2=list(kick_projects_copy)\nfeatures_2.remove('state')\nfeatures_2_numerical = [e for e in features_2 if e not in ('category','main_category','country','currency')]\nfeatures_2_categorical = ['category','main_category','country','currency']\nresponse = ['state']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5cfe3d7edbb1b80ab124c1e6cf6cc03608b844c"
      },
      "cell_type": "code",
      "source": "# Assuming same lines from your example\ncols_to_norm = features_2_numerical\nkick_projects_copy[cols_to_norm] = kick_projects_copy[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a6c98c77b02395f55d7b54f573f8faeb2c02f0d"
      },
      "cell_type": "code",
      "source": "#creating test and train dependent and independent variables\n#Split the data into test and train (30-70: random sampling)\n#will be using the scaled dataset to split \ntrain_ind_2, test_ind_2, train_dep_2, test_dep_2 = train_test_split(kick_projects_copy[features_2],kick_projects_copy[response], test_size=0.3, random_state=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "745a7a113577314d586bb4caf1f95d9ee15ee56e"
      },
      "cell_type": "code",
      "source": "#create LGBM classifier model\ngbm_model_2 = lgb.LGBMClassifier(\n        boosting_type= \"dart\",\n        n_estimators=1500,\n        learning_rate=0.05,\n        num_leaves=38,\n        colsample_bytree=.8,\n        subsample=.9,\n        max_depth=9,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n)\n\n# LGBM with one-hot encoded features\n#fit the model on training data\ngbm_model_2=gbm_model_2.fit(train_ind_2[features_2], \n            train_dep_2[response], \n            feature_name=features_2,\n            categorical_feature= features_2_categorical,                \n              verbose=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "35a12e82cdd50260664a7b9e1c48a576b0f78a26"
      },
      "cell_type": "markdown",
      "source": "#### Predictions using LGBM (version 2)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08b9c4f7011cd5cd9045fdfc6ecd1261fb683a4f"
      },
      "cell_type": "code",
      "source": "# Predict the on the train_data\ntest_ind_2[\"Pred_state_LGB\"] = gbm_model_2.predict(test_ind_2[features_2])\n\n# Predict the on the train_data\ntrain_ind_2[\"Pred_state_LGB\"] = gbm_model_2.predict(train_ind_2[features_2])\n\n# Predict the on the train_data\nkick_projects_copy[\"Pred_state_LGB\"] = gbm_model_2.predict(kick_projects_copy[features_2])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "013f6e34f34d40179cd2f7da31e2af59d7e07a85"
      },
      "cell_type": "markdown",
      "source": "#### Evaluating model performance"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7bfd2aa1e123e1a848852c13a4377f9edc97439"
      },
      "cell_type": "code",
      "source": "# Train and Test Accuracy\nprint (\"Train Accuracy :: \", accuracy_score(train_dep_2[response], gbm_model_2.predict(train_ind_2[features_2])))\nprint (\"Test Accuracy  :: \", accuracy_score(test_dep_2[response], gbm_model_2.predict(test_ind_2[features_2])))\nprint (\"Complete Accuracy  :: \", accuracy_score(kick_projects_copy[response], gbm_model_2.predict(kick_projects_copy[features_2])))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_copy[response],kick_projects_copy[\"Pred_state_LGB\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a451e954630ae2b96fdef46254e4fd5ca221426"
      },
      "cell_type": "code",
      "source": "# classification matrix\nprint('\\nClassification metrics')\nprint(classification_report(y_true=test_dep_2[response], y_pred=gbm_model_2.predict(test_ind_2[features_2])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e68b04aaebdea519a9b30e4471f64552610c4708"
      },
      "cell_type": "markdown",
      "source": "#### Feature Importances"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87e9407da0f708277d03de348190d4e964adf7bc"
      },
      "cell_type": "code",
      "source": "## Feature importances\nftr_imp_lgb_2=zip(features_2,gbm_model_2.feature_importances_)\n\nfor values in ftr_imp_lgb_2:\n    print(values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36211475bf15e24d90440508bbb93917831098ea"
      },
      "cell_type": "code",
      "source": "# creating a dataframe to get top features\nfeature_imp_lgb_2=pd.DataFrame(list(zip(features_2,gbm_model_2.feature_importances_)))\ncolumn_names_lgb_2= ['features','LGB_imp_2']\nfeature_imp_lgb_2.columns= column_names_lgb_2\n\nfeature_imp_lgb_2= feature_imp_lgb_2.sort_values('LGB_imp_2',ascending=False)\nfeature_imp_lgb_2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7c2857fea278ea61171674d1702a9878e9e8babb"
      },
      "cell_type": "markdown",
      "source": "Since we see category is coming out to be abnormally high in importance, treating it..."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39d8fd8ac0af3c206683ad133beefc6b1995b13f"
      },
      "cell_type": "code",
      "source": "class LGBMClassifier_GainFE(lgb.LGBMClassifier):\n    @property\n    def feature_importances_(self):\n        if self._n_features is None:\n            raise LGBMNotFittedError('No feature_importances found. Need to call fit beforehand.')\n        return self.booster_.feature_importance(importance_type='gain')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65110f3ddedf056d480b7d026d5c81dd7d00e148"
      },
      "cell_type": "code",
      "source": "# defining parameters\nlgb_gain = LGBMClassifier_GainFE(boosting_type= \"dart\",\n        n_estimators=1500,\n        learning_rate=0.05,\n        num_leaves=38,\n        colsample_bytree=.8,\n        subsample=.9,\n        max_depth=9,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "817cc91046c491d170c7b8f21ae8327e1eefb824"
      },
      "cell_type": "code",
      "source": "#fitting the model\nlgb_gain.fit(train_ind_2[features_2], \n            train_dep_2[response], \n            feature_name=features_2,\n            categorical_feature= features_2_categorical,                \n              verbose=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bb2961da91d332cbe9c87c6382e80a9b48dc12e7"
      },
      "cell_type": "markdown",
      "source": "#### Predictions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03e3a2cb65d2f81f77476dd8e829ac0fc69efce5"
      },
      "cell_type": "code",
      "source": "# Predict the on the train_data\ntest_ind_2[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(test_ind_2[features_2])\n\n# Predict the on the train_data\ntrain_ind_2[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(train_ind_2[features_2])\n\n# Predict the on the train_data\nkick_projects_copy[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(kick_projects_copy[features_2])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "350a39a513c533ea172e6aeb4896300e968203a2"
      },
      "cell_type": "markdown",
      "source": "#### Model Evaluation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f857f695dd10cc934317383c17ceb9d476a1c660"
      },
      "cell_type": "code",
      "source": "# Train and Test Accuracy\nprint (\"Train Accuracy :: \", accuracy_score(train_dep_2[response], lgb_gain.predict(train_ind_2[features_2])))\nprint (\"Test Accuracy  :: \", accuracy_score(test_dep_2[response], lgb_gain.predict(test_ind_2[features_2])))\nprint (\"Complete Accuracy  :: \", accuracy_score(kick_projects_copy[response], lgb_gain.predict(kick_projects_copy[features_2])))\nprint (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_copy[response],kick_projects_copy[\"Pred_state_LGB_Gain\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a334dab56ff80a4a300befaa101f07b57d1bc59a"
      },
      "cell_type": "markdown",
      "source": "#### Feature Importance "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3e02a6f88d92eee0a4ec6b11f0f70dda8d4a171"
      },
      "cell_type": "code",
      "source": "## Feature importances\nftr_imp_lgb_gain=zip(features_2,lgb_gain.feature_importances_)\n\nfor values in ftr_imp_lgb_gain:\n    print(values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96274f86c7e5fffe35b001eb89233aa8d44e221d"
      },
      "cell_type": "code",
      "source": "# creating a dataframe to get top 15 features\nftr_imp_lgb_gain=pd.DataFrame(list(zip(features_2,lgb_gain.feature_importances_)))\ncolumn_names_lgb_gain= ['features','LGB_gain_imp']\nftr_imp_lgb_gain.columns= column_names_lgb_gain\n\nftr_imp_lgb_gain= ftr_imp_lgb_gain.sort_values('LGB_gain_imp',ascending=False)\nftr_imp_lgb_gain[:15]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2cf3818c40f46b66327069f8b6912aa8e3a14c96"
      },
      "cell_type": "markdown",
      "source": "This still gives a similar feature list. Category is still the most important feature."
    },
    {
      "metadata": {
        "_uuid": "e27df719f8470b67497ba507e2213750b29fcd81"
      },
      "cell_type": "markdown",
      "source": "## Ensemble Classifiers"
    },
    {
      "metadata": {
        "_uuid": "f9ac8e453ca0bef423a688894a09d4b5d9546cf9"
      },
      "cell_type": "markdown",
      "source": "### Simple Ensemble: Average Probabailities"
    },
    {
      "metadata": {
        "_uuid": "3885bc6df5352e4ca5504ced7e96dfcb7c099533",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import tree\nfrom sklearn import neighbors\nimport math",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76897ccf408ff78d27c7913d93f1ad6636934c8c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_dtc_g = tree.DecisionTreeClassifier()\nmodel_dtc_e = tree.DecisionTreeClassifier(criterion=\"entropy\")\nmodel_knn = neighbors.KNeighborsClassifier()\nmodel_lr= LogisticRegression(penalty='l1',solver='saga')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "336af42d4d78dee53f7203afdc8c9f3521da22c9",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_dtc_g.fit(train_ind[features], train_dep[response])\nmodel_dtc_e.fit(train_ind[features], train_dep[response])\nmodel_knn.fit(train_ind[features], train_dep[response])\nmodel_lr.fit(train_ind[features], train_dep[response])\n\npred_dtc_g=model_dtc_g.predict_proba(test_ind[features])\npred_dtc_e=model_dtc_e.predict_proba(test_ind[features])\npred_knn=model_knn.predict_proba(test_ind[features])\npred_lr=model_lr.predict_proba(test_ind[features])\n\nfinalpred=(pred_dtc_g+pred_dtc_e+pred_knn+pred_lr)/4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2768a0ee452df7d4dda837dcfc0e6b94a1427722",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_proba_avg=pd.DataFrame(finalpred)\ncol_names=['prob_0','prob_1']\npred_proba_avg.columns=col_names",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a18ab0c25c05180c4a8dff22d093b8634d0bdead",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def final_state(c):\n    if c['prob_0'] >c['prob_1']:\n        return 0\n    else:\n        return 1\n    \npred_proba_avg['final_state_avg'] = pred_proba_avg.apply(final_state, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bcff7e65e8ea0190cd1b43a96eaee1d1f68c5df",
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_ind = test_ind.reset_index(drop=True)\npred_proba_avg = pred_proba_avg.reset_index(drop=True)\ntest_ind=pd.concat([test_ind,pred_proba_avg],axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "31372e04eec3a1e1165128e81b67185a24e14adf",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print (\"Test Accuracy  :: \", accuracy_score(test_dep[response],test_ind['final_state_avg']))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be2fb41eb876eb3f65c3b7236d4285fcf4b06542"
      },
      "cell_type": "markdown",
      "source": "### Boosting"
    },
    {
      "metadata": {
        "_uuid": "ad8263a89418f5cb073710f8c49357afdf5185b0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import AdaBoostClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b9cf55a96ff077d4825448cc5822ac66c174fcc1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_ada = AdaBoostClassifier(random_state=1)\nmodel_ada.fit(train_ind[features], train_dep[response])\nmodel_ada.score(test_ind[features],test_dep[response])",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}